# -*- coding: utf-8 -*-
"""SVM_Diabetes_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uYJ22H0lw-evjd3Ly20wI3IzMKYM06e-

## Import the dependencies
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

"""## Data Collection and Analysis"""

# loading the diabetes dataset
diabetes_dataset = pd.read_csv('diabetes.csv')

diabetes_dataset.head() #Dataset includes data for all the females only.

diabetes_dataset.shape

diabetes_dataset.describe()

diabetes_dataset["Outcome"].value_counts()
# 500 none diabetic cases
# 268 diabetic cases

diabetes_dataset.groupby('Outcome').mean()

import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(15,7))
sns.heatmap(diabetes_dataset.corr(),annot=True)

X = diabetes_dataset.drop("Outcome",axis=1)
Y = diabetes_dataset["Outcome"]

scaler = StandardScaler()

scaler.fit(X)

standardized_data = scaler.transform(X)

X = standardized_data
y = diabetes_dataset["Outcome"]

"""## Train Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=Y,random_state=42)
#Stratify - So that equal amounts of datas from the otput column goes to the train and test no bhedd bhaav

"""### Training The Model"""

classifier = svm.SVC(kernel='linear')

# Training the support vector machine classifier
classifier.fit(X_train, y_train)

"""## Evaluating our Model"""

predictions = classifier.predict(X_test)
print(accuracy_score(y_test,predictions))

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test,predictions))
print(classification_report(y_test, predictions))

"""## Grid Search"""

from sklearn.model_selection import GridSearchCV

param_grid = {"C":[0.1,1,10,100],
             'gamma':[1,0.1,0.01,0.001]}

grid = GridSearchCV(svm.SVC(),param_grid,verbose=2)
grid.fit(X_train, y_train)

grid_preds = grid.predict(X_test)

print(confusion_matrix(y_test, grid_preds))

print(classification_report(y_test, grid_preds))

"""## Making a predictive System"""

input_data = (1,103,30,38,83,43.3,0.183,33)

# Turning input data into numpy array as it is easier
input_data_as_numpy_array = np.asarray(input_data)

#Reshape the data
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

#Also we will have to standardize the data as our training data is standardized
std_data = scaler.transform(input_data_reshaped)
print(std_data)

prediction = classifier.predict(std_data)
print(prediction) #It is correct

if prediction[0] == 0:
  print("The person is not diabetic")
else:
  print("The person is diabetic")

